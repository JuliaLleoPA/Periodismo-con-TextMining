{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber limpiado nuestro texto, preparamos el formato de los datos para utilizarlos más tarde. En este caso, prepararemos y almacenaremos los datos en forma de **corpus** y **matriz**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:orange\"> CREACIÓN DEL CORPUS </span>\n",
    "___\n",
    "Nuestro corpus estará compuesto por el conjunto de noticias seleccionadas por  periódico debidamente limpiadas y almacenadas como cadena de texto. Como nos interesa realizar un análisis comparativo, se ha previsto como solución al conflicto la creación de un marco de datos **DataFrame** del paquete **Pandas**. De esta forma podremos almacenar la información en forma de tabulación, y así diferenciar la pertenencia de las noticias a sus correspondientes medios. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el paquete previamente instalado\n",
    "import pandas as pd\n",
    "\n",
    "'''Personalizamos la representación'''\n",
    "pd.set_option('max_colwidth',200)\n",
    "\n",
    "'''Habremos guardado nuestros datos en un diccionario que contenga: Clave (nombre del periódico) - Valor(cadena de texto limpio)'''\n",
    "corpus_df = pd.DataFrame.from_dict(diccionario).transpose()\n",
    "\n",
    "'''Llamamos a la columna Noticias'''\n",
    "corpus_df.columns = ['Noticias']\n",
    "\n",
    "'''Con este método Pandas ordena las etiquetas con sus debidos ejes'''\n",
    "corpus_df = corpus_df.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos nuevamente nuestra serialización pickle\n",
    "corpus_df.to_pickle(\"corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:orange\"> CREACIÓN DE LA MATRIZ </span>\n",
    "___\n",
    "\n",
    "Para nuestro análisis también necesitaremos crear una *bolsa de palabras* que registre el número de apariciones de cada característica lingüística en nuestros textos. Esta bolsa de palabras es un elemento común dentro del campo del PLN, y consiste en un modelo de representación del vocabulario utilizado mediante una matriz en la que se miden el número de apariciones del token por campo. \n",
    "Para poder hacer esta conversión a una matriz matemática, pasaremos por vectorizar nuestro texto. Los pasos a seguir serán:\n",
    "* \tTokenización del texto\n",
    "*\tCreación de un vocabulario\n",
    "*\tCodificación del documento\n",
    "\n",
    "Para nuestra investigación utilizaremos la clase **CountVectorizer** de la biblioteca de aprendizaje automático **Scikit-learn**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:blue\"> ANTES DE CREAR LA MATRIZ </span>\n",
    "___\n",
    "Antes de proceder a crear la matriz es conveniente eliminar aquellas *palabras vacías* como artículos, pronombres, preposiciones e incluso algunos verbos modales o auxiliares. Para nuestro modelo hemos creado un conjunto de 395 palabras vacías que recogemos en el archivo `palabras_vacias`. \n",
    "Para la creación de este corpus se ha tenido en cuenta que uno de nuestros objetivos es el cálculo de sentimiento, por lo que se han mantenido adjetivos calificativos y adverbios de cantidad, afirmación, negación, duda y modo que en otras situaciones serían considerados como palabras vacías. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el módulo codecs, que nos ahorrará problemas con la codificación y decodificación de nuestro documento\n",
    "\n",
    "import codecs \n",
    "\n",
    "with codecs.open('palabras_vacias.txt', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos CountVectorizer para crear la matriz, excluyendo las palabras definidas como vacías\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "'''Especificamos la exclusión de nuestra lista de palabras vacías'''\n",
    "cv = CountVectorizer(stop_words = stopwords)\n",
    "\n",
    "'''La función transform convertirá a un vector nuestra columna de texto'''\n",
    "matriz_cv = cv.fit_transform(corpus_df.Noticias)\n",
    "\n",
    "'''Expresamos su resultado de nuevo en una tabla DataFrame'''\n",
    "df_matriz = pd.DataFrame(matriz_cv.toarray(), columns=cv.get_feature_names())\n",
    "df_matriz.index = corpus_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De nuevo, guardamos para posterior uso\n",
    "\n",
    "df_matriz.to_pickle(\"df_matriz.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#También guardamos nuestro elemento CountVectorizer para posterior uso en la detección de temas automática\n",
    "\n",
    "pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
