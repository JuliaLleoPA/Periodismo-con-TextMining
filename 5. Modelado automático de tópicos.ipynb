{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:orange\"> MODELADO DEL TEMA CON LDA </span>\n",
    "___\n",
    "El modelado de tema es otra de las técnicas más comunes dentro de los análisis del PLN. Se trata de un recurso que detecta automáticamente abstracciones de temas en una colección de documentos mediante comparaciones estadísticas. \n",
    "Existen diferentes técnicas a la hora de llevar a cabo esta tarea, siempre basadas en el aprendizaje no supervisado, como son las técnicas Correlated Topic Model o el Biterm Topic Model. En nuestro caso, escogeremos el algoritmo *Latent Dirichlet Allocation* (LDA), ya que ha sido específicamente formulado para tipos de datos textuales y es, actualmente, la técnica más explorada dentro de los análisis de Procesamiento de Lenguaje Natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar con el algoritmo, recurrimos al modelo LDA de la librería **gensim**. Este paquete se inicia a partir de una bolsa de palabras (en nuestro caso, de la matriz). Los pasos que seguiremos son:\n",
    "-\tCreación de una matriz dispersa a partir de la nuestra\n",
    "-\tGeneración de un corpus gensim propio con esa matriz\n",
    "-\tRecolección de los identificadores de las palabras presentes en nuestro contador de vectores\n",
    "-\tLlamada a las funciones del modelo especificando algunos parámetros\n",
    "-\tObservación de la relación que automáticamente se genera entre temas valorados y nuestros corpus cargados, y valoración de su adecuación\n",
    "-\tRepetición de los últimos dos pasos hasta concluir con un resultado significativo. Por último, poner nombre a estos temas “descubiertos” y observar qué tema destaca más en cada periódico. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previamente deberemos haber instalado gensim en nuestro sistema\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos la matriz de términos\n",
    "import pandas as pd\n",
    "\n",
    "matriz = pd.read_pickle('df_matriz.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''De nuevo, trasladamos la matriz original de forma que cada columna corresponda a un periódico'''\n",
    "matriz = matriz.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a hacer una matriz dispersa con nuestra matriz, para después crear el corpus gensim\n",
    "\n",
    "cuenta_dispersas = scipy.sparse.csr_matrix(matriz)\n",
    "corpus = matutils.Sparse2Corpus(cuenta_dispersas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para la LDA también necesitaremos el objeto CountVectorizer definido en la etapa 3.Creación del corpus y la matriz \n",
    "\n",
    "cv = pickle.load(open(\"cv.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo ponemos en marcha\n",
    "\n",
    "'''Debemos especificar el número de topics que creemos puede haber y el número de veces que recorrerá el texto.\n",
    "Estos dos valores podemos variarlos hasta obtener un resultado relevante'''\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=100)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos qué abtracción de tema destaca más en cada corpus\n",
    "\n",
    "corpus_transformado = lda[corpus]\n",
    "list(zip([a for [(a, b)] in corpus_transformado], matriz.index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
